{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: OpenAI in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from OpenAI) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from OpenAI) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from OpenAI) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from OpenAI) (2.6.1)\n",
      "Requirement already satisfied: sniffio in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from OpenAI) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from OpenAI) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from OpenAI) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from anyio<5,>=3.5.0->OpenAI) (3.4)\n",
      "Requirement already satisfied: certifi in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from httpx<1,>=0.23.0->OpenAI) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from pydantic<3,>=1.9.0->OpenAI) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from pydantic<3,>=1.9.0->OpenAI) (2.16.2)\n",
      "Requirement already satisfied: colorama in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from tqdm>4->OpenAI) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whisper-mic\n",
      "  Downloading whisper_mic-1.4.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting attrs\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.8/60.8 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.0/57.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from whisper-mic) (1.26.1)\n",
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
      "     -------------------------------------- 798.6/798.6 kB 8.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pyaudio in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from whisper-mic) (0.2.14)\n",
      "Requirement already satisfied: pydantic in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from whisper-mic) (2.6.1)\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting pynput\n",
      "  Downloading pynput-1.7.6-py2.py3-none-any.whl (89 kB)\n",
      "     ---------------------------------------- 89.2/89.2 kB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from whisper-mic) (2.31.0)\n",
      "Collecting rich\n",
      "  Using cached rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "Collecting speechrecognition\n",
      "  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n",
      "     --------------------------------------- 32.8/32.8 MB 10.7 MB/s eta 0:00:00\n",
      "Collecting tdqm\n",
      "  Downloading tdqm-0.0.1.tar.gz (1.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torch in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from whisper-mic) (2.2.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "     ---------------------------------------- 8.4/8.4 MB 10.7 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-7.0.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: colorama in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from click->whisper-mic) (0.4.6)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     ------------------------------------- 840.9/840.9 kB 13.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Collecting numba\n",
      "  Downloading numba-0.59.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 11.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from openai-whisper->whisper-mic) (4.66.1)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-win_amd64.whl (798 kB)\n",
      "     ------------------------------------- 798.7/798.7 kB 10.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from pydantic->whisper-mic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from pydantic->whisper-mic) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from pydantic->whisper-mic) (4.8.0)\n",
      "Requirement already satisfied: six in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from pynput->whisper-mic) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from requests->whisper-mic) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from requests->whisper-mic) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from requests->whisper-mic) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from requests->whisper-mic) (2023.7.22)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from rich->whisper-mic) (2.16.1)\n",
      "Requirement already satisfied: filelock in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch->whisper-mic) (3.13.1)\n",
      "Requirement already satisfied: sympy in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch->whisper-mic) (1.12)\n",
      "Requirement already satisfied: networkx in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch->whisper-mic) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch->whisper-mic) (3.1.3)\n",
      "Requirement already satisfied: fsspec in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch->whisper-mic) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers->whisper-mic) (0.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers->whisper-mic) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers->whisper-mic) (6.0.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl (269 kB)\n",
      "     ------------------------------------- 269.5/269.5 kB 17.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers->whisper-mic) (0.15.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.2-cp311-none-win_amd64.whl (269 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from jinja2->torch->whisper-mic) (2.1.3)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0\n",
      "  Downloading llvmlite-0.42.0-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "     --------------------------------------- 28.1/28.1 MB 10.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from sympy->torch->whisper-mic) (1.3.0)\n",
      "Building wheels for collected packages: openai-whisper, tdqm, future\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801375 sha256=f5c65409be6fe0843bb25428dc99e5e5053e6eadf8b95d7a3f237da8e5f7a2e8\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\b7\\ca\\33\\94a2e7f1f7c1922acdff1c62566a6376c6e94809e72f41c72d\n",
      "  Building wheel for tdqm (setup.py): started\n",
      "  Building wheel for tdqm (setup.py): finished with status 'done'\n",
      "  Created wheel for tdqm: filename=tdqm-0.0.1-py3-none-any.whl size=1334 sha256=ad89e235ea0407a8cee4bc4aab74515b6053fb0c0554764fd7d0447f5c9010f1\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\40\\00\\a1\\82f6130290786ab4c0aff81491e5dea540de593cd677da2278\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492054 sha256=dafce2307c28d7fcccf0d70154e294e6be4d1f093543bfe3114bac4495d6b68c\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\83\\31\\5a\\7539ed9c6ac3249781de831638629a4fe503168023e1a777e2\n",
      "Successfully built openai-whisper tdqm future\n",
      "Installing collected packages: pydub, zipp, safetensors, regex, pynput, more-itertools, mdurl, llvmlite, future, click, attrs, tiktoken, tdqm, speechrecognition, numba, markdown-it-py, importlib-metadata, ffmpeg-python, rich, openai-whisper, transformers, whisper-mic\n",
      "Successfully installed attrs-23.2.0 click-8.1.7 ffmpeg-python-0.2.0 future-0.18.3 importlib-metadata-7.0.1 llvmlite-0.42.0 markdown-it-py-3.0.0 mdurl-0.1.2 more-itertools-10.2.0 numba-0.59.0 openai-whisper-20231117 pydub-0.25.1 pynput-1.7.6 regex-2023.12.25 rich-13.7.0 safetensors-0.4.2 speechrecognition-3.10.1 tdqm-0.0.1 tiktoken-0.6.0 transformers-4.37.2 whisper-mic-1.4.0 zipp-3.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install whisper-mic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faster-whisper in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (0.10.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pyaudio in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: wave in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: transformers in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: torchaudio in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (2.2.0)\n",
      "Collecting pyttsx3\n",
      "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: av==10.* in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from faster-whisper) (10.0.0)\n",
      "Requirement already satisfied: ctranslate2<4,>=3.22 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from faster-whisper) (3.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from faster-whisper) (0.20.3)\n",
      "Requirement already satisfied: tokenizers<0.16,>=0.13 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from faster-whisper) (0.15.1)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from faster-whisper) (1.17.0)\n",
      "Requirement already satisfied: filelock in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: torch==2.2.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torchaudio) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch==2.2.0->torchaudio) (4.8.0)\n",
      "Requirement already satisfied: sympy in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch==2.2.0->torchaudio) (1.12)\n",
      "Requirement already satisfied: networkx in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch==2.2.0->torchaudio) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch==2.2.0->torchaudio) (3.1.3)\n",
      "Requirement already satisfied: fsspec in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from torch==2.2.0->torchaudio) (2024.2.0)\n",
      "Collecting comtypes\n",
      "  Downloading comtypes-1.3.0-py3-none-any.whl (194 kB)\n",
      "     ------------------------------------- 194.1/194.1 kB 12.3 MB/s eta 0:00:00\n",
      "Collecting pypiwin32\n",
      "  Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: pywin32 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from pyttsx3) (306)\n",
      "Requirement already satisfied: setuptools in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from ctranslate2<4,>=3.22->faster-whisper) (65.5.0)\n",
      "Requirement already satisfied: coloredlogs in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (23.5.26)\n",
      "Requirement already satisfied: protobuf in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (4.25.0)\n",
      "Requirement already satisfied: colorama in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from jinja2->torch==2.2.0->torchaudio) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from sympy->torch==2.2.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in e:\\coding\\pythonlearning\\machinelearning\\imageclassification\\imageclassification\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (3.4.1)\n",
      "Installing collected packages: comtypes, pypiwin32, pyttsx3\n",
      "Successfully installed comtypes-1.3.0 pypiwin32-223 pyttsx3-2.90\n"
     ]
    }
   ],
   "source": [
    "pip install faster-whisper pyaudio wave transformers torchaudio pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\coding\\pythonLearning\\MachineLearning\\ImageClassification\\imageClassification\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from faster_whisper import WhisperModel\n",
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 21:55:38,657 INFO wav2vec_microphone.main()\n",
      "Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-english and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torch\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s %(message)s')\n",
    "logging.info(\"wav2vec_microphone.main()\")\n",
    "\n",
    "model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "\n",
    "sampling_rate = 16000\n",
    "record_time_in_seconds = 5\n",
    "number_of_samples = round(record_time_in_seconds * sampling_rate)\n",
    "\n",
    "def stt():\n",
    "    mic_stream = pyaudio.PyAudio().open(format=pyaudio.paInt16,\n",
    "                            channels=1,\n",
    "                            rate=sampling_rate,\n",
    "                            input=True,\n",
    "                            frames_per_buffer=number_of_samples)\n",
    "\n",
    "    # Get audio\n",
    "    logging.info(\"Speak!\")\n",
    "    speech_arr = np.frombuffer(mic_stream.read(number_of_samples), dtype=np.int16)\n",
    "    print(speech_arr)\n",
    "\n",
    "    speech_tsr = torch.from_numpy(speech_arr)\n",
    "    # Tokenize our tensor\n",
    "    input_values = processor(speech_tsr, return_tensord=\"pt\", sampling_rate=sampling_rate)[\"input_values\"]\n",
    "    input_tsr = torch.from_numpy(input_values[0]).to(device).unsqueeze(0)\n",
    "\n",
    "    # Perform inference\n",
    "    logits = model(input_tsr)[\"logits\"]\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    logging.info(f\"type(predicted_ids) = {type(predicted_ids)}; predicted_ids.shape = {predicted_ids.shape}\")\n",
    "\n",
    "    # Decode the IDs to text\n",
    "    transcription = processor.decode(predicted_ids[0]).lower()\n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 21:55:41,198 INFO Imported existing <module 'comtypes.gen' from 'e:\\\\coding\\\\pythonLearning\\\\MachineLearning\\\\ImageClassification\\\\imageClassification\\\\Lib\\\\site-packages\\\\comtypes\\\\gen\\\\__init__.py'>\n",
      "2024-02-10 21:55:41,199 INFO Using writeable comtypes cache directory: 'e:\\coding\\pythonLearning\\MachineLearning\\ImageClassification\\imageClassification\\Lib\\site-packages\\comtypes\\gen'\n"
     ]
    }
   ],
   "source": [
    "engine = pyttsx3.init()\n",
    "    \n",
    "rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "engine.setProperty('rate', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 21:55:56,286 INFO HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! I'm an AI assistant designed to help you with a variety of tasks. How can I assist you today?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 21:56:03,191 INFO Speak!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[-32 -62 -62 ...  32  33  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_30328\\266110212.py:33: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  speech_tsr = torch.from_numpy(speech_arr)\n",
      "2024-02-10 21:56:12,076 INFO type(predicted_ids) = <class 'torch.Tensor'>; predicted_ids.shape = torch.Size([1, 249])\n",
      "2024-02-10 21:56:12,095 INFO HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India is a country located in South Asia, and it is the seventh-largest country by land area and the second-most populous country in the world. It is known for its diverse culture, rich history, and beautiful landscapes, including the Himalayas, beaches, and ancient ruins. India has a rich literary and artistic heritage, and it is home to many famous festivals, such as Diwali, Holi, and Navratri. The country also has a vibrant food scene, with a wide variety of cuisines to choose from"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 21:56:28,880 INFO Speak!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "[ -70 -107  -89 ...   81   91   96]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 21:56:35,426 INFO type(predicted_ids) = <class 'torch.Tensor'>; predicted_ids.shape = torch.Size([1, 249])\n",
      "2024-02-10 21:56:35,445 INFO HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angela Woltman is an American writer who is best known for her science fiction novel \"The Tomorrow War.\" The book tells the story of a scientist named Dr. Cathy Fish who works on a top-secret government project and becomes embroiled in a war with alien invaders. The novel has received positive reviews for its engaging plot, well-developed characters, and thought-provoking themes. If you enjoyed \"The Tomorrow War,\" you may also want to check out other science fiction novels by Angela Woltman or similar authors"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 21:56:51,918 INFO Speak!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "[ 11  20  17 ... 100  99  97]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")\n",
    "\n",
    "def main():\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an intelligent assistant. You always provide well-reasoned answers that are both correct and helpful.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, introduce yourself to someone opening this program for the first time. Be concise.\"},\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"local-model\", # this field is currently unused\n",
    "            messages=history,  \n",
    "            temperature=0.7,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        new_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "        end_msg = 0\n",
    "        \n",
    "        for chunk in completion:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                print(chunk.choices[0].delta.content, end=\"\")       \n",
    "                new_message[\"content\"] += chunk.choices[0].delta.content\n",
    "                if (new_message[\"content\"].find('.') != -1):\n",
    "                        engine.say(new_message[\"content\"][end_msg:len(new_message[\"content\"])])\n",
    "                        engine.runAndWait()\n",
    "                        end_msg += len(new_message[\"content\"])\n",
    "        history.append(new_message)\n",
    "\n",
    "        print()\n",
    "        history.append({\"role\": \"user\", \"content\": stt()})\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageClassification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
